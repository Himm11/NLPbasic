{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himm11/NLPbasic/blob/main/Tf_Idf_Vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SK3IM5QQGr4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiAwmtmJQGr6"
      },
      "outputs": [],
      "source": [
        "#so let’s load our sentences and combine them together in a single set :\n",
        "first_sentence = \"Data Science is the sexiest job of the 21st century\"\n",
        "second_sentence = \"machine learning is the key for data science\"\n",
        "#split so each word have their own string\n",
        "first_sentence = first_sentence.split(\" \")\n",
        "second_sentence = second_sentence.split(\" \")#join them to remove common duplicate words\n",
        "total= set(first_sentence).union(set(second_sentence))\n",
        "print(total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd_zYdk9QGr7"
      },
      "outputs": [],
      "source": [
        "#Now lets add a way to count the words using a dictionary key-value pairing for both sentences :\n",
        "wordDictA = dict.fromkeys(total, 0)\n",
        "wordDictB = dict.fromkeys(total, 0)\n",
        "for word in first_sentence:\n",
        "    wordDictA[word]+=1\n",
        "\n",
        "for word in second_sentence:\n",
        "    wordDictB[word]+=1\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm4vBHc5QGr8",
        "outputId": "b9e3bfcf-3049-4c80-b06b-b00cf9b12b61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>machine</th>\n",
              "      <th>learning</th>\n",
              "      <th>for</th>\n",
              "      <th>is</th>\n",
              "      <th>century</th>\n",
              "      <th>of</th>\n",
              "      <th>Data</th>\n",
              "      <th>science</th>\n",
              "      <th>the</th>\n",
              "      <th>job</th>\n",
              "      <th>21st</th>\n",
              "      <th>sexiest</th>\n",
              "      <th>Science</th>\n",
              "      <th>data</th>\n",
              "      <th>key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   machine  learning  for  is  century  of  Data  science  the  job  21st  \\\n",
              "0        0         0    0   1        1   1     1        0    2    1     1   \n",
              "1        1         1    1   1        0   0     0        1    1    0     0   \n",
              "\n",
              "   sexiest  Science  data  key  \n",
              "0        1        1     0    0  \n",
              "1        0        0     1    1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now we put them in a dataframe and then view the result:\n",
        "pd.DataFrame([wordDictA, wordDictB])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH76qRWBQGr9"
      },
      "outputs": [],
      "source": [
        "#No let’s writing the TF Function :\n",
        "def computeTF(wordDict, doc):\n",
        "    tfDict = {}\n",
        "    corpusCount = len(doc)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count/float(corpusCount)\n",
        "    return(tfDict)\n",
        "#running our sentences through the tf function:\n",
        "tfFirst = computeTF(wordDictA, first_sentence)\n",
        "tfSecond = computeTF(wordDictB, second_sentence)\n",
        "#Converting to dataframe for visualization\n",
        "tf = pd.DataFrame([tfFirst, tfSecond])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDdJlAgCQGr-",
        "outputId": "bc13e1bf-ccd8-4148-b68e-a86531f84b36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>machine</th>\n",
              "      <th>learning</th>\n",
              "      <th>for</th>\n",
              "      <th>is</th>\n",
              "      <th>century</th>\n",
              "      <th>of</th>\n",
              "      <th>Data</th>\n",
              "      <th>science</th>\n",
              "      <th>the</th>\n",
              "      <th>job</th>\n",
              "      <th>21st</th>\n",
              "      <th>sexiest</th>\n",
              "      <th>Science</th>\n",
              "      <th>data</th>\n",
              "      <th>key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   machine  learning    for     is  century   of  Data  science    the  job  \\\n",
              "0    0.000     0.000  0.000  0.100      0.1  0.1   0.1    0.000  0.200  0.1   \n",
              "1    0.125     0.125  0.125  0.125      0.0  0.0   0.0    0.125  0.125  0.0   \n",
              "\n",
              "   21st  sexiest  Science   data    key  \n",
              "0   0.1      0.1      0.1  0.000  0.000  \n",
              "1   0.0      0.0      0.0  0.125  0.125  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LwqRv-TQGr_",
        "outputId": "381e3d52-9dfd-4959-c80b-0ddf147c9c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nThat’s all for TF formula , just i wanna talk about stop words that we should eliminate them because they are the most commonly occurring words which don’t give any additional value to the document vector .in-fact removing these will increase computation and space efficiency.\\nnltk library has a method to download the stopwords, so instead of explicitly mentioning all the stopwords ourselves we can just use the nltk library and iterate over all the words and remove the stop words. There are many efficient ways to do this, but ill just give a simple method.\\nthose a sample of a stopwords in english language :\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "That’s all for TF formula , just i wanna talk about stop words that we should eliminate them because they are the most commonly occurring words which don’t give any additional value to the document vector .in-fact removing these will increase computation and space efficiency.\n",
        "nltk library has a method to download the stopwords, so instead of explicitly mentioning all the stopwords ourselves we can just use the nltk library and iterate over all the words and remove the stop words. There are many efficient ways to do this, but ill just give a simple method.\n",
        "those a sample of a stopwords in english language :\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gQaPNHXQGr_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_sentence = [w for w in wordDictA if not w in stop_words]\n",
        "print(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB7ZkbKJQGsA"
      },
      "outputs": [],
      "source": [
        "#And now that we finished the TF section, we move onto the IDF part:\n",
        "def computeIDF(docList):\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "\n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
        "\n",
        "    return(idfDict)\n",
        "#inputing our sentences in the log file\n",
        "idfs = computeIDF([wordDictA, wordDictB])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iTYGWerQGsA",
        "outputId": "51b5ddac-590a-43bb-b0b9-595c4900f6a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    machine  learning       for        is   century        of      Data  \\\n",
            "0  0.000000  0.000000  0.000000  0.030103  0.030103  0.030103  0.030103   \n",
            "1  0.037629  0.037629  0.037629  0.037629  0.000000  0.000000  0.000000   \n",
            "\n",
            "    science       the       job      21st   sexiest   Science      data  \\\n",
            "0  0.000000  0.060206  0.030103  0.030103  0.030103  0.030103  0.000000   \n",
            "1  0.037629  0.037629  0.000000  0.000000  0.000000  0.000000  0.037629   \n",
            "\n",
            "        key  \n",
            "0  0.000000  \n",
            "1  0.037629  \n"
          ]
        }
      ],
      "source": [
        "#and now we implement the idf formula , let’s finish with calculating the TFIDF\n",
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return(tfidf)\n",
        "#running our two sentences through the IDF:\n",
        "idfFirst = computeTFIDF(tfFirst, idfs)\n",
        "idfSecond = computeTFIDF(tfSecond, idfs)\n",
        "#putting it in a dataframe\n",
        "idf= pd.DataFrame([idfFirst, idfSecond])\n",
        "print(idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuqL0g_2QGsB"
      },
      "outputs": [],
      "source": [
        "#That was a lot of work. But it is handy to know, if you are asked to code TF-IDF from scratch in the future. However, this can be done a lot simpler thanks to sklearn library. Let’s look at the example from them below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIwiFsv_QGsB"
      },
      "outputs": [],
      "source": [
        "#first step is to import the library\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#for the sentence, make sure all words are lowercase or you will run #into error. for simplicity, I just made the same sentence all #lowercase\n",
        "firstV= \"Data Science is the sexiest job of the 21st century\"\n",
        "secondV= \"machine learning is the key for data science\"\n",
        "#calling the TfidfVectorizer\n",
        "vectorize= TfidfVectorizer()\n",
        "#fitting the model and passing our sentences right away:\n",
        "response= vectorize.fit_transform([firstV, secondV])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv1JzW0eQGsC",
        "outputId": "84813291-260d-4bdd-d52f-35d73625084c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 1)\t0.34211869506421816\n",
            "  (0, 0)\t0.34211869506421816\n",
            "  (0, 9)\t0.34211869506421816\n",
            "  (0, 5)\t0.34211869506421816\n",
            "  (0, 11)\t0.34211869506421816\n",
            "  (0, 12)\t0.48684053853849035\n",
            "  (0, 4)\t0.24342026926924518\n",
            "  (0, 10)\t0.24342026926924518\n",
            "  (0, 2)\t0.24342026926924518\n",
            "  (1, 3)\t0.40740123733358447\n",
            "  (1, 6)\t0.40740123733358447\n",
            "  (1, 7)\t0.40740123733358447\n",
            "  (1, 8)\t0.40740123733358447\n",
            "  (1, 12)\t0.28986933576883284\n",
            "  (1, 4)\t0.28986933576883284\n",
            "  (1, 10)\t0.28986933576883284\n",
            "  (1, 2)\t0.28986933576883284\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk0ynyfCQGsC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}